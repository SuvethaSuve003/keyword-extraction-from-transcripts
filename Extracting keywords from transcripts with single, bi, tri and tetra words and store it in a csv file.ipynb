{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2284c5ca",
   "metadata": {},
   "source": [
    "Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2cd51b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import csv\n",
    "from csv import writer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from flashtext import KeywordProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4e69e3",
   "metadata": {},
   "source": [
    "Read a file and print its filename and its content in a dictionary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b33d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_filename_contents={}                        #empty dictionary for appending the values\n",
    "\n",
    "directory = 'transcriptss'                       #folder which contains all the files\n",
    "\n",
    "for filename in os.listdir(directory):           #listing the directories\n",
    "    file = os.path.join(directory, filename)     #getting the filename from the directory\n",
    "    with open(file , 'r') as file:               #open a file in a read mode\n",
    "        contents = file.readlines()              #read the contents inside the file\n",
    "    dict_filename_contents[filename] = contents  #printing the contents of a file to a dictionary\n",
    "#dict_filename_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92aaf6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                  #we are keeping it in a pandas format\n",
    "data_df = pd.DataFrame.from_dict(dict_filename_contents).transpose()  \n",
    "data_df.columns = ['transcript']                  #transcripts for the column name \n",
    "#data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34eebd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42097/3762335551.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_df['transcript'] = data_df['transcript'].str.replace('\\d+', '')\n"
     ]
    }
   ],
   "source": [
    "data_df['transcript'] = data_df['transcript'].str.replace('\\d+', '') \n",
    "                                                  #deleting int values because we dont need them\n",
    "#print(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a796c7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_extraction_flashtext():\n",
    "    #keyword_processor.add_keywords_from_dict(keyword_dict)\n",
    "    keywordprocessor = KeywordProcessor()  #case sensitive is not a problem in flashtext\n",
    "    keywordprocessor.add_keyword('MOTHER') #keywords...\n",
    "    keywordprocessor.add_keyword('FATHER')\n",
    "    keywordprocessor.add_keyword('COLLEGE')\n",
    "    keywordprocessor.add_keyword('COME FROM')\n",
    "    keywordprocessor.add_keyword('MY HOMETOWN')\n",
    "    keywordprocessor.add_keyword('I STAY IN')\n",
    "    keywordprocessor.add_keyword('MY AREA OF INTEREST')\n",
    "    keywordprocessor.add_keyword('I WOULD LIKE TO')\n",
    "    keywordprocessor.add_keyword('MY STRENGTHS ARE')\n",
    "    keywordprocessor.add_keyword('MY STRENGTH IS')\n",
    "    keywordprocessor.add_keyword('TITLE OF PROJECT')\n",
    "    keywordprocessor.add_keyword('NAME OF PROJECT')\n",
    "    keywordprocessor.add_keyword('I AM WORKING ON')\n",
    "    keywordprocessor.add_keyword('I WANT TO')\n",
    "    \n",
    "    data_df['transcripts'] = data_df['transcripts'].apply(lambda x: len(keywordprocessor.extract_keywords(x)))   \n",
    "    print(data_df.head())   \n",
    "    \n",
    "#keyword_extraction_flashtext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f93c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score():\n",
    "    keywords_with_weights = {\"MOTHER\":14, \n",
    "                         \"FATHER\":13,\n",
    "                         \"COLLEGE\":12,\n",
    "                         \"COME FROM\":11,\n",
    "                         \"MY HOMETOWN\":10,\n",
    "                         \"I STAY IN\":9,\n",
    "                         \"MY AREA OF INTEREST\":8,\n",
    "                         \"I WOULD LIKE TO\":7,\n",
    "                         \"MY STRENGTHS ARE\":6,\n",
    "                         \"MY STRENGTH IS\":5,\n",
    "                         \"TITLE OF PROJECT\":4,\n",
    "                         \"NAME OF PROJECT\":3,\n",
    "                         \"I AM WORKING ON\":2,\n",
    "                         \"I WANT TO\":1,\n",
    "                       }                         #assigning weights for each keywords\n",
    "    weights = {}    #empty dictionary for storing the appended values\n",
    "    for keys,values in keywords_with_weights.items():     #looping through the key and values in the dicti \n",
    "        for i in Extractedkeywords1:      #looping through the extracted keywords\n",
    "            if i==keys:                   #comparing the extracted keywords and the keys in the dicti if matches go on.\n",
    "                weights[keys] = values    #storing the values in the empty dictionary\n",
    "    #print(weights)                        #print the weights\n",
    "    \n",
    "    extractedkey_values = weights.values()       #getting the values for summing up\n",
    "    #print(extractedkey_values)\n",
    "    \n",
    "    score = sum(extractedkey_values)                    #sum the values for score\n",
    "    #print(score)\n",
    "    \n",
    "#calculate_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe72cd7b",
   "metadata": {},
   "source": [
    "document term matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "957321f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtm_single_word():\n",
    "                                                   #document-term matrix using CountVectorizer, and exclude common English stop words\n",
    "    cv = CountVectorizer(stop_words='english')     #for removing stop words\n",
    "    data_cv = cv.fit_transform(data_df.transcript) #fit the data for training\n",
    "    data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names()) \n",
    "                                                   #getting the feature names in the columns\n",
    "    data_dtm.index = data_df.index                 #for index we are giving the index values of the pandas dataframe\n",
    "    #print(data_dtm)\n",
    "    df = data_dtm.sum(axis=0)                      #sum of a each keywords in all the transcripts\n",
    "    df_single = df.sort_values(ascending=False)    #sorting the values in a descending order of the sum\n",
    "    print(df_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9901eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtm_bigram():\n",
    "                                                   #document-term matrix using CountVectorizer, and exclude common English stop words\n",
    "    cv_bi = CountVectorizer(stop_words='english', ngram_range=(2, 2))      \n",
    "                                                   #for removing stop words  #bigram\n",
    "    data_cv_bi = cv_bi.fit_transform(data_df.transcript)  \n",
    "                                                   #fit the data for training\n",
    "    data_dtm_bi = pd.DataFrame(data_cv_bi.toarray(), columns=cv_bi.get_feature_names()) \n",
    "                                                   #getting the feature names in the columns\n",
    "    data_dtm_bi.index = data_df.index              #for index we are giving the index values of the pandas dataframe\n",
    "    #print(data_dtm_bi)\n",
    "    df_bi = data_dtm_bi.sum(axis=0)                #sum of a each keywords in all the transcripts\n",
    "    df_bigram = df_bi.sort_values(ascending=False) #sorting the values in a descending order of the sum\n",
    "    print(df_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e8e1eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtm_trigram():\n",
    "                                                   #document-term matrix using CountVectorizer, and exclude common English stop words\n",
    "    cv_tri = CountVectorizer(stop_words='english', ngram_range=(3, 3))      \n",
    "                                                   #for removing stop words   #tri-gram\n",
    "    data_cv_tri = cv_tri.fit_transform(data_df.transcript)  \n",
    "                                                   #fit the data for training\n",
    "    data_dtm_tri = pd.DataFrame(data_cv_tri.toarray(), columns=cv_tri.get_feature_names()) \n",
    "                                                   #getting the feature names in the columns\n",
    "    data_dtm_tri.index = data_df.index             #for index we are giving the index values of the pandas dataframe\n",
    "    #print(data_dtm_tri)\n",
    "    df_tri = data_dtm_tri.sum()                    #sum of a each keywords in all the transcripts\n",
    "    df_trigram = df_tri.sort_values(ascending=False)\n",
    "                                                   #sorting the values in a descending order of the sum\n",
    "    print(df_trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84c3db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtm_tetragram():\n",
    "                                                    #document-term matrix using CountVectorizer, and exclude common English stop words\n",
    "    cv_four = CountVectorizer(stop_words='english', ngram_range=(4, 4))      \n",
    "                                                    #for removing stop words, #tetra-gram\n",
    "    data_cv_four = cv_four.fit_transform(data_df.transcript)                 \n",
    "                                                    #fit the data for training\n",
    "    data_dtm_four = pd.DataFrame(data_cv_four.toarray(), columns=cv_four.get_feature_names()) \n",
    "                                                    #getting the feature names in the columns\n",
    "    data_dtm_four.index = data_df.index             #for index we are giving the index values of the pandas dataframe\n",
    "    #print(data_dtm_four)\n",
    "    df_four = data_dtm_four.sum()                   #sum of all the feature values\n",
    "    df_fourgram = df_four.sort_values(ascending=False)\n",
    "                                                    #sorting the values in a descending order of the sum\n",
    "    print(df_fourgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d06a5822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtm_single_with_stopword():\n",
    "                                                    #document-term matrix using CountVectorizer, and exclude common English stop words\n",
    "    cv_stopword = CountVectorizer()\n",
    "    data_cv_stopword = cv_stopword.fit_transform(data_df.transcript)  \n",
    "                                                    #fit the data for training\n",
    "    data_dtm_stopword = pd.DataFrame(data_cv_stopword.toarray(), columns=cv_stopword.get_feature_names()) \n",
    "                                                    #getting the feature names in the columns\n",
    "    data_dtm_stopword.index = data_df.index         #for index we are giving the index values of the pandas dataframe\n",
    "    #print(data_dtm_stopword)\n",
    "    df1_single_stopword = data_dtm_stopword.sum(axis=0)  \n",
    "                                                    #sum of a each keywords in all the transcripts\n",
    "    df_single_stopword = df1_single_stopword.sort_values(ascending=False)        \n",
    "                                                    #sorting the values in a descending order of the sum\n",
    "    print(df_single_stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5660c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtm_bigram_with_stopword():\n",
    "                                                    #document-term matrix using CountVectorizer, and exclude common English stop words\n",
    "    cv_bi_stopword = CountVectorizer(ngram_range=(2, 2))      \n",
    "                                                    #for removing stop words  #bigram\n",
    "    data_cv_bi_stopword = cv_bi_stopword.fit_transform(data_df.transcript)  \n",
    "                                                    #fit the data for training\n",
    "    data_dtm_bi_stopword = pd.DataFrame(data_cv_bi_stopword.toarray(), columns=cv_bi_stopword.get_feature_names()) \n",
    "                                                    #getting the feature names in the columns\n",
    "    data_dtm_bi_stopword.index = data_df.index      #for index we are giving the index values of the pandas dataframe\n",
    "    #print(data_dtm_bi_stopword)\n",
    "    df_bi_stopword = data_dtm_bi_stopword.sum(axis=0) \n",
    "                                                    #sum of a each keywords in all the transcripts\n",
    "    df_bigram_stopword = df_bi_stopword.sort_values(ascending=False)      \n",
    "                                                    #sorting the values in a descending order of the sum\n",
    "    print(df_bigram_stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17595866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtm_trigram_with_stopword():\n",
    "                                                    #document-term matrix using CountVectorizer, and exclude common English stop words\n",
    "    cv_tri_stopword = CountVectorizer(ngram_range=(3, 3))      \n",
    "                                                    #for removing stop words   #tri-gram\n",
    "    data_cv_tri_stopword = cv_tri_stopword.fit_transform(data_df.transcript)  \n",
    "                                                    #fit the data for training\n",
    "    data_dtm_tri_stopword = pd.DataFrame(data_cv_tri_stopword.toarray(), columns=cv_tri_stopword.get_feature_names()) \n",
    "                                                    #getting the feature names in the columns\n",
    "    data_dtm_tri_stopword.index = data_df.index     #for index we are giving the index values of the pandas dataframe\n",
    "    #print(data_dtm_tri_stopword)\n",
    "    df_tri_stopword = data_dtm_tri_stopword.sum()   #sum of a each keywords in all the transcripts\n",
    "    df_trigram_stopword = df_tri_stopword.sort_values(ascending=False)     \n",
    "                                                    #sorting the values in a descending order of the sum\n",
    "    print(df_trigram_stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae28f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtm_tetragram_with_stopword():\n",
    "                                                 #document-term matrix using CountVectorizer, and exclude common English stop words\n",
    "    cv_four_stopword = CountVectorizer(ngram_range=(4, 4))      \n",
    "                                                 #for removing stop words, #tetra-gram\n",
    "    data_cv_four_stopword = cv_four_stopword.fit_transform(data_df.transcript)                 \n",
    "                                                 #fit the data for training\n",
    "    data_dtm_four_stopword = pd.DataFrame(data_cv_four_stopword.toarray(), columns=cv_four_stopword.get_feature_names()) #getting the feature names in the columns\n",
    "    data_dtm_four_stopword.index = data_df.index #for index we are giving the index values of the pandas dataframe\n",
    "    #print(data_dtm_four_stopword)\n",
    "    df_four_stopword = data_dtm_four_stopword.sum()                       \n",
    "                                                 #sum of all the feature values\n",
    "    df_fourgram_stopword = df_four_stopword.sort_values(ascending=False)  \n",
    "                                                 #sorting the values in a descending order of the sum\n",
    "    print(df_fourgram_stopword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cd7141",
   "metadata": {},
   "source": [
    "Function calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f96a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm_single_word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "740fc71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm_bigram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc4d6b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm_trigram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0cbd471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm_tetragram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6c3d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm_single_with_stopword()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ded4e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm_bigram_with_stopword()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56d80ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm_trigram_with_stopword()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c6cf18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm_tetragram_with_stopword()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14519d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword_extraction_flashtext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9506acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7395f447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
